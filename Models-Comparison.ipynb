{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import segmentation_models_3D as sm\n",
    "import custom_datagenerator as datagen\n",
    "from unet_basic import simple_unet_model\n",
    "import unet_attent\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training weights\n",
    "#wt0 = 0.26;wt1 = 22.53;wt2 = 22.53;wt3 = 26.21\n",
    "# Redefine the loss\n",
    "#dice_loss = sm.losses.DiceLoss(class_weights = np.array([wt0,wt1,wt2,wt3]))\n",
    "#focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "#total_loss = dice_loss + (1 * focal_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the required paths\n",
    "# Training\n",
    "train_img_path = \"data_dir/trainval/train/images\"\n",
    "train_mask_path = \"data_dir/trainval/train/masks\"\n",
    "train_img_list = sorted(os.listdir(train_img_path))\n",
    "train_mask_list = sorted(os.listdir(train_mask_path))\n",
    "# Validation\n",
    "val_img_path = \"data_dir/trainval/val/images\"\n",
    "val_mask_path = \"data_dir/trainval/val/masks\"\n",
    "val_img_list = sorted(os.listdir(val_img_path))\n",
    "val_mask_list = sorted(os.listdir(val_mask_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the test generator\n",
    "batch_size = 4\n",
    "test_img_datagen = datagen.imageLoader(val_img_path, \n",
    "                                       val_img_list, \n",
    "                                       val_mask_path, \n",
    "                                       val_mask_list,\n",
    "                                       batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the original Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Import the model so that it can be trained further\n",
    "modelV1 = load_model(\"models/brats_3d.hdf5\", compile=False)\n",
    "modelV2 = load_model(\"models/brats_3dV2.hdf5\", compile=False)\n",
    "model_attention = load_model(\"models/brats_3dAttention.hdf5\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_test_images = 86\n",
    "# Initalize arrays to store all actual and all predictions from the generator\n",
    "all_actual = np.zeros((number_of_test_images//batch_size, 4, 128, 128, 128))\n",
    "all_preds = all_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the new generator\n",
    "for i in range(number_of_test_images//batch_size):\n",
    "    test_image_batch, test_mask_batch = test_img_datagen.__next__()\n",
    "    \n",
    "    test_mask_batch_argmax = np.argmax(test_mask_batch, axis = 4)\n",
    "    test_pred_batch = modelV1.predict(test_image_batch)\n",
    "    test_pred_batch_argmax = np.argmax(test_pred_batch, axis = 4)\n",
    "    \n",
    "    if test_mask_batch_argmax.shape[0] == 2:\n",
    "        print(i)\n",
    "    else:\n",
    "        all_actual[i] = test_mask_batch_argmax\n",
    "        all_preds[i] = test_pred_batch_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU for all batches of test images 0.6906448602676392\n"
     ]
    }
   ],
   "source": [
    "n_classes = 4\n",
    "for i in range(all_actual.shape[0]):\n",
    "    IoU_vals = tf.metrics.MeanIoU(num_classes=n_classes)\n",
    "    IoU_vals.update_state(test_pred_batch_argmax, test_mask_batch_argmax)\n",
    "    if i == 0:\n",
    "        meanIoU = IoU_vals.result().numpy()\n",
    "    else:\n",
    "        meanIoU = (meanIoU + IoU_vals.result().numpy()) / 2\n",
    "        \n",
    "print(f\"Mean IoU for all batches of test images {meanIoU}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the 2nd version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_test_images = 86\n",
    "# Initalize arrays to store all actual and all predictions from the generator\n",
    "all_actual = np.zeros((number_of_test_images//batch_size, 4, 128, 128, 128))\n",
    "all_preds = all_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Testing the new generator\n",
    "for i in range(number_of_test_images//batch_size):\n",
    "    test_image_batch, test_mask_batch = test_img_datagen.__next__()\n",
    "    \n",
    "    test_mask_batch_argmax = np.argmax(test_mask_batch, axis = 4)\n",
    "    test_pred_batch = modelV2.predict(test_image_batch)\n",
    "    test_pred_batch_argmax = np.argmax(test_pred_batch, axis = 4)\n",
    "    \n",
    "    if test_mask_batch_argmax.shape[0] == 2:\n",
    "        print(i)\n",
    "    else:\n",
    "        all_actual[i] = test_mask_batch_argmax\n",
    "        all_preds[i] = test_pred_batch_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU for all batches of test images 0.6582146883010864\n"
     ]
    }
   ],
   "source": [
    "n_classes = 4\n",
    "for i in range(all_actual.shape[0]):\n",
    "    IoU_vals = tf.metrics.MeanIoU(num_classes=n_classes)\n",
    "    IoU_vals.update_state(test_pred_batch_argmax, test_mask_batch_argmax)\n",
    "    if i == 0:\n",
    "        meanIoU = IoU_vals.result().numpy()\n",
    "    else:\n",
    "        meanIoU = (meanIoU + IoU_vals.result().numpy()) / 2\n",
    "        \n",
    "print(f\"Mean IoU for all batches of test images {meanIoU}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the attention 3d unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_test_images = 86\n",
    "# Initalize arrays to store all actual and all predictions from the generator\n",
    "all_actual = np.zeros((number_of_test_images//batch_size, 4, 128, 128, 128))\n",
    "all_preds = all_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Testing the new generator\n",
    "for i in range(number_of_test_images//batch_size):\n",
    "    test_image_batch, test_mask_batch = test_img_datagen.__next__()\n",
    "    \n",
    "    test_mask_batch_argmax = np.argmax(test_mask_batch, axis = 4)\n",
    "    test_pred_batch = model_attention.predict(test_image_batch)\n",
    "    test_pred_batch_argmax = np.argmax(test_pred_batch, axis = 4)\n",
    "    \n",
    "    if test_mask_batch_argmax.shape[0] == 2:\n",
    "        print(i)\n",
    "    else:\n",
    "        all_actual[i] = test_mask_batch_argmax\n",
    "        all_preds[i] = test_pred_batch_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU for all batches of test images 0.5875717401504517\n"
     ]
    }
   ],
   "source": [
    "n_classes = 4\n",
    "for i in range(all_actual.shape[0]):\n",
    "    IoU_vals = tf.metrics.MeanIoU(num_classes=n_classes)\n",
    "    IoU_vals.update_state(test_pred_batch_argmax, test_mask_batch_argmax)\n",
    "    if i == 0:\n",
    "        meanIoU = IoU_vals.result().numpy()\n",
    "    else:\n",
    "        meanIoU = (meanIoU + IoU_vals.result().numpy()) / 2\n",
    "        \n",
    "print(f\"Mean IoU for all batches of test images {meanIoU}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
